{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "The data has been split into two groups:\n",
    "\n",
    "training set (train.csv)\n",
    "test set (test.csv)\n",
    "The training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use feature engineering to create new features.\n",
    "\n",
    "The test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
    "\n",
    "We also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTALLING PACKAGES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we start by importing the necessary libraries for data manipulation and viz\n",
    "## !pip install seaborn\n",
    "## !pip install statsmodels\n",
    "\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "%matplotlib inline \n",
    "# Esse comando serve para plotar os gráficos estáticos logo abaixo da célula,\n",
    "\n",
    "# existem outras configurações do %matplolib que podem mostrar os gráficos em outras abas ou gráficos dinâmicos.\n",
    "# Por padrão, desde a versão 3.7 do python anaconda, a configuração padrão do %matplotlib já é o inline.\n",
    "# https://ipython.readthedocs.io/en/stable/interactive/plotting.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding some ML capabilities with Scikit-learn\n",
    "## !pip install scikit-learn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTING DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COLUMNS DESCRIPTION**\n",
    "\n",
    ". passengerid = ID do passageiro do navio (código primário).\n",
    "\n",
    ". survived = Se sobreviveu ao naufrágio estará como 1 e caso esteja com 0 (zero) não sobreviveu.\n",
    "\n",
    ". pclass = Tipo de classe de passagem (Do 1 ao 3), (1 = 1st, 2 = 2nd, 3 = 3rd).\n",
    "\n",
    ". name = Nome do passageiro\n",
    "\n",
    ". sex = Gênero do passageiro, sendo masculino e feminino.\n",
    "\n",
    ". age = Idade do passageiro na data da ocorrência do naufrágio.\n",
    "\n",
    ". sibsp = Número de irmãos / cônjuges a bordo.\n",
    "\n",
    ". parch = Número de pais / filhos a bordo.\n",
    "\n",
    ". ticket = Código do ticket.\n",
    "\n",
    ". fare = Valor da passagem.\n",
    "\n",
    ". cabin = Código de identificação da Cabine.\n",
    "\n",
    ". embarked = Local ondem o passageiro embarcou no navio: C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the train dataset and verifying the first info\n",
    "titanic = pd.read_csv('train.csv')\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same thing for the test dataset\n",
    "titanic_test = pd.read_csv('test.csv')\n",
    "titanic_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXPLORATORY ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some detail on our columns\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the NAs\n",
    "titanic.isna().sum()\n",
    "\n",
    "#isna() returns true (or 1) when the value is non existent (NaN) then we can .sum() the colum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or, to be more complete, let's see the proportion of NaN in each column\n",
    "pd.DataFrame(\n",
    "    zip(    ##zip joins two tupples\n",
    "        titanic.isna().sum(),               ##first column\n",
    "        titanic.isna().sum()/len(titanic)   ##second column\n",
    "    ),\n",
    "    columns = ['Count', 'Proportion'],\n",
    "    index = titanic.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see some quantitative description of our dataset\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our target variable is the \"Survived\" column. Let's see how many people survived\n",
    "\n",
    "titanic.Survived.value_counts()/len(titanic)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INITIALIZING PRE-PROCESSING**\n",
    "\n",
    "Starting by KDD process - Knowledge Discovery in Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('kdd.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I always like to start with pairplot. It shows the distribution of some variables and we can vizualise the possible correlation between them\n",
    "# but in this case is not that impressive\n",
    "sb.pairplot(titanic[['Survived','Age','Fare','Sex', 'Pclass']].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Seaborn version:\", sb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets check the variable fare\n",
    "\n",
    "##sb.histplot(data = titanic, x=\"Fare\")\n",
    "sb.histplot(titanic['Fare'])\n",
    "\n",
    "\n",
    "## seaborn is a great library for image plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(data = titanic, x = \"Survived\", y = \"Fare\")\n",
    "plt.title(\"Fare distribution for survivals and non survivals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's eliminate some outliers from the \"Fare\" columns\n",
    "\n",
    "titanic.loc[titanic['Fare']>=300]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can truncate these three values to the maximum of Fare = 300\n",
    "\n",
    "titanic.loc[titanic['Fare']>=300, 'Fare'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeating the same plot as before\n",
    "sb.boxplot(data = titanic, x = \"Survived\", y = \"Fare\")\n",
    "plt.title(\"Fare distribution for survivals and non survivals - Truncating outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the age of passengers\n",
    "\n",
    "sb.histplot(data = titanic, x = 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(data = titanic, y = 'Age', x = 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUSBSTITUTING NaN VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Completing NaN values\n",
    "print('Age info:\\nAverage= {} \\nMedian = {}'.format(titanic['Age'].mean(), titanic['Age'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluating for sex\n",
    "C_median = titanic['Age'].groupby(by= titanic.Sex).median()\n",
    "\n",
    "C_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluating for class\n",
    "C_median = titanic['Age'].groupby(by= titanic.Pclass).median()\n",
    "\n",
    "C_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will find the mean age for each class/sex group\n",
    "\n",
    "trainMeans = titanic.groupby(['Sex','Pclass'])['Age'].mean()\n",
    "\n",
    "trainMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying the averages\n",
    "\n",
    "def age_estimate(x):\n",
    "    if not np.isnan(x['Age']):                  ## if age is not NaN\n",
    "        return x['Age']                         ## return itself (the age)\n",
    "    return trainMeans[x[\"Sex\"], x['Pclass']]    ## otherwise retuns the age calculated in the trainMeans formula\n",
    "\n",
    "\n",
    "titanic['Age'] = titanic.apply(age_estimate, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUALITATIVE PREDICTIVE VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluatint effect of \"Sex\"\n",
    "titanic.groupby('Survived')['Sex'].value_counts().unstack(0).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluatint effect of where the passager embarked\n",
    "titanic.groupby('Survived')['Embarked'].value_counts().unstack(0).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all NAN (only 2 values) of the \"Embarked\" column with the Mode\n",
    "\n",
    "titanic['Embarked'] = titanic['Embarked'].fillna('S')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATING DUMMIES FOR QUALITATIVE VARIABLES**\n",
    "\n",
    "Some algorithms have dificulties in evaluating categorical values. \n",
    "Specially if the category is represented as a numerical value.\n",
    "In this case, one strategy is to create what we call dummy columns, one hot enconding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('hot encoding dummy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 'get_dummies' method will evaluate the column selected and return True or false for each possible value\n",
    "pd.get_dummies(titanic['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the 'dropfirst' is commonly used, because you if you have n possible results...\n",
    "#you can determine all the values with n-1 columns (i.e, if all columns return False, the dropped column would be True)\n",
    "pd.get_dummies(titanic['Sex'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a column that says if the passanger is male or not\n",
    "titanic['male'] = pd.get_dummies(\n",
    "    titanic['Sex'],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing the same for the embarked place\n",
    "embark_dummies = pd.get_dummies(\n",
    "    titanic['Embarked'], #This time we will do the same for the embarked column\n",
    "    drop_first=True, #dropping the first column (should be C)\n",
    "    prefix='Embarked_' #putting a prefix so we end up with Embarked_Q and Embarked_S columns\n",
    ")\n",
    "\n",
    "embark_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding these columns to my dataframe with the concat method\n",
    "titanic = pd.concat(\n",
    "    [ titanic , embark_dummies ],   #the two dataframes we want to unite\n",
    "    axis=1                          #the axis=1 indicate we will concatenate the dataframes horizontally (add columns)\n",
    ")\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do not need the \"Sex\" or \"Embarked\" columns anymore\n",
    "titanic.drop(\n",
    "    ['Sex','Embarked'],     # the columns to be dropped\n",
    "    axis = 1,               # the axis of drop (1 means column)\n",
    "    inplace=True            # means we will substitute the original dataframe\n",
    ")\n",
    "\n",
    "#The inplace true means we will replace the original dataframe. It is the same as if we had typed:\n",
    "#titanic = titanic.drop(['Sex','Embarked'],axis = 1)\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WORKING ON OTHER QUALITATIVE VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's review where we are so far\n",
    "\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pclass is described as Int64 because the value is numerical (1, 2 or 3)\n",
    "#But we do not want our model to view it as a quantitative value\n",
    "#so we change to class\n",
    "\n",
    "titanic['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Pclass'] = titanic['Pclass'].astype('category')\n",
    "titanic['Survived'] = titanic['Survived'].astype('bool')\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's create our dummies for Pclass\n",
    "pclass_dummies = pd.get_dummies(\n",
    "    titanic['Pclass'],              #Create a dummy that returns the columns \n",
    "    drop_first=True,                #Droppint the Pclass_1 column that will not be necessary\n",
    "    prefix=\"Pclass_\"                #Pclass_2 and #Pclass_3\n",
    ")\n",
    "\n",
    "titanic = pd.concat(\n",
    "    [ titanic , pclass_dummies ],   #the two dataframes we want to unite\n",
    "    axis=1                          #the axis=1 indicate we will concatenate the dataframes horizontally (add columns)\n",
    ")\n",
    "\n",
    "titanic.drop(\n",
    "    ['Pclass'],                     #with the dummies ready, we do not need the original Pclass column\n",
    "    axis = 1,\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##finally, let's drop the individual values that will not contribute to the machine learning\n",
    "titanic_train = titanic.drop(['PassengerId','Name','Cabin', 'Ticket'], axis=1)\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SEPARATING TEST AND TRAIN DATA**\n",
    "\n",
    "In this phase we divide our train model in two parts\n",
    "\n",
    "one part will be used to train the model\n",
    "\n",
    "the other part will evaluate the assertiveness of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using the train_test_split from SKLEARN\n",
    "\n",
    "'''\n",
    "(function) def train_test_split(\n",
    "    *arrays: Any,\n",
    "    test_size: Float | None = None,\n",
    "    train_size: Float | None = None,\n",
    "    random_state: Int | RandomState | None = None,\n",
    "    shuffle: bool = True,\n",
    "    stratify: ArrayLike | None = None\n",
    ") -> list\n",
    "\n",
    "Split arrays or matrices into random train and test subsets.\n",
    "\n",
    "Quick utility that wraps input validation, next(ShuffleSplit().split(X, y)), \n",
    "and application to input data into a single call for splitting (and optionally subsampling) data into a one-liner.\n",
    "'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    titanic_train.drop('Survived',axis=1),          # independent values, will be the dataframe without the target column\n",
    "    titanic_train['Survived'],                      # dependent value, target column\n",
    "    test_size=0.10,                                 # how much of the dataframe will be used for testing (in this case 90% will be used for training)\n",
    "    random_state=10                                 # including a random state just ensures the result of the shuffle will always be the same for this block\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##X_train is the matrix of values that the model will use to try and understand the behaviour of y_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##after the training, the model will try to apply the resulting formula into the X_test values, and see if got correct results when comparing\n",
    "##to the y_test results\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"adding one line to see if clearoutput is working\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
